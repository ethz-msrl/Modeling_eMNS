import numpy as np
import os
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import math
import pandas as pd
import os
import os.path
import glob
import re
import tensorflow as tf

def read_stats_file(fn):
    stats = np.loadtxt(fn)
    r2 = stats[0,:]
    rmse = stats[1,:]
    mae = stats[2,:]
    return r2, rmse, mae

def get_ranges(args_file):
    """
    Gets the magnetic field range from the args file generated by deep-fluids to perform denormalization
    """
    args = {}
    with open(args_file, 'r') as f:
        while True:
            line = f.readline()
            if not line:
                break
            arg, arg_value = line[:-1].split(': ')
            args[arg] = arg_value
    c_num = int(args['num_param'])
    p_min = float(args['min_c'])
    p_max = float(args['max_c'])
    p_num = int(args['num_param'])
    y_range = []
    y_num = []
    for i in range(c_num):
        p_min = float(args['min_c'])
        p_max = float(args['max_c'])
        p_num = int(args['num_param'])
        y_range.append([p_min, p_max])
        y_num.append(p_num)
    r = [float(args['min_b']), float(args['max_b'])]
    x_range = max(abs(r[0]), abs(r[1]))
    return x_range, y_range

def denorm(x_range, y_range, x=None, y=None):
    # input range [-1, 1] -> original range
    if x is not None:
        x *= x_range

    if y is not None:
        r = y_range
        for i, ri in enumerate(y_range):
            y[i] = (y[i]+1) * 0.5 * (ri[1]-ri[0]) + ri[0]
    return x, y

def rounddown(x, level=5.0):
    return int(math.floor(x / level) * level)

def create_df(data_dir, test_dir, test_idx_fn, x_range, y_range):
    obs_data = []
    pred_data = []
    currents = []
    test_idx = np.loadtxt(test_idx_fn, dtype=int)
    for idx in test_idx:
        obs_data_fn = os.path.join(data_dir, '%04d.npz' % idx)
        obs_data_f = np.load(obs_data_fn)
        obs_data.append(obs_data_f['x'].reshape(-1,3))
        pred_data_fn = os.path.join(test_dir, '%04d.npz' % idx)
        pred_data_f = np.load(pred_data_fn)
        pred_data.append(pred_data_f['x'].reshape(-1,3))
        _, pred_current = denorm(x_range, y_range, None, np.squeeze(pred_data_f['y']))
        # checking that the currents are the same in the prediction and observation
        assert(np.allclose(obs_data_f['y'], pred_current))
        currents.append(np.tile(obs_data_f['y'], (obs_data[-1].shape[0], 1)))
    obs_data = np.array(obs_data).reshape(-1, 3)
    pred_data = np.array(pred_data).reshape(-1, 3)
    currents = np.array(currents).reshape(-1,8)

    currents_cols = ['I%d' % i for i in range(currents.shape[1])]
    column_names = ['Ox', 'Oy', 'Oz'] + ['Px', 'Py', 'Pz'] + currents_cols
    test_df = pd.DataFrame(data=np.concatenate((obs_data, pred_data, currents), axis=1), columns=column_names)
    test_df['max_currents_mag'] = np.max(np.abs(test_df[currents_cols]), axis=1)
    test_df['currents_level'] = test_df['max_currents_mag'].apply(rounddown)
    return test_df

def evaluate_generic_metrics(labels, predictions):
    # label_norm = np.sqrt(np.sum(labels**2, axis=1))
    # prediction_norm = np.sqrt(np.sum(predictions**2, axis=1))
    label_norm = [np.linalg.norm(y) for y in labels]
    prediction_norm = [np.linalg.norm(y) for y in predictions]

    # R^2
    r2_c = r2_score(y_true=labels, y_pred=predictions, multioutput='raw_values')
    r2 = r2_score(y_true=labels, y_pred=predictions)
    r2_norm = r2_score(y_true=label_norm, y_pred=prediction_norm)

    # Root mean squared error
    rmse_c = np.sqrt(mean_squared_error(y_true=labels, y_pred=predictions, multioutput='raw_values'))
    rmse = np.sqrt(mean_squared_error(y_true=labels, y_pred=predictions))
    nrmse = rmse / (np.max(predictions) - np.min(predictions))
    rmse_norm = np.sqrt(mean_squared_error(y_true=label_norm, y_pred=prediction_norm))
    mae_c = mean_absolute_error(labels, predictions, multioutput='raw_values')
    mae = mean_absolute_error(labels, predictions)
    nmae = mean_absolute_error(labels, predictions) / (np.max(predictions) - np.min(predictions))
    mae_norm = mean_absolute_error(label_norm, prediction_norm)

    return {"R2_x": r2_c[0],
            "R2_y": r2_c[1],
            "R2_z": r2_c[2],
            "R2": r2,
            "R2_norm": r2_norm,
            "MAE_mT" : mae * 1000,
            "RMSE_mT": rmse * 1000,
            "N-RMSE": nrmse,
            "RMSE_x_mT": rmse_c[0]*1000,
            "RMSE_y_mT": rmse_c[1]*1000,
            "RMSE_z_mT": rmse_c[2]*1000,
            "RMSE_mT": rmse*1000,
            "RMSE_norm_mT": rmse_norm*1000,
            "MAE_x_mT": 1000*mae_c[0],
            "MAE_z_mT": 1000*mae_c[1],
            "MAE_y_mT": 1000*mae_c[2],
            "MAE_norm_mT": 1000*mae_norm,
            "N-MAE": nmae} 

def extract_stats(root_path):
    ss_paths = glob.glob(os.path.join(root_path, '*_ep_*'))
    r2_l = []
    rmse_l = []
    epoch_l = []
    mae_l = []
    for path in sorted(ss_paths):
        epoch = int(re.findall(r'[\d]+$',path)[0])
        stats_file = tf.train.latest_checkpoint(path) + '.test_stats'
        if not os.path.exists(stats_file):
            print('could not find stats file for %s' % path)
            continue

        r2, rmse, mae = read_stats_file(stats_file)
        r2_l.append(r2)
        rmse_l.append(rmse)
        mae_l.append(mae)
        epoch_l.append(epoch)
        
    r2s = np.array(r2_l)
    rmses = 1000 * np.array(rmse_l)
    maes = 1000 * np.array(mae_l)
    epochs = np.array(epoch_l)
    ret = {
        'r2s': r2s,
        'maes': maes,
        'epochs': epochs,
        'rmses': rmses
    }
    return ret